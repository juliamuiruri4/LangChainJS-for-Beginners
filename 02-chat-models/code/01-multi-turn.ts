/**
 * Example 1: Multi-Turn Conversation
 *
 * Learn how to have back-and-forth conversations by maintaining
 * conversation history in a messages array.
 *
 * Run: npx tsx 02-chat-models/code/01-multi-turn.ts
 */

import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, AIMessage, SystemMessage } from "@langchain/core/messages";
import "dotenv/config";

async function main() {
  console.log("ðŸ’¬ Multi-Turn Conversation Example\n");

  const model = new ChatOpenAI({
    model: "gpt-4o-mini",
    configuration: {
      baseURL: "https://models.inference.ai.azure.com",
    },
    apiKey: process.env.GITHUB_TOKEN,
  });

  // Start with system message and first question
  const messages = [
    new SystemMessage("You are a helpful coding tutor who gives clear, concise explanations."),
    new HumanMessage("What is TypeScript?"),
  ];

  console.log("ðŸ‘¤ User: What is TypeScript?");

  // First exchange
  const response1 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response1.content);

  // Add AI response to conversation history
  messages.push(new AIMessage(response1.content));

  // Second exchange - AI remembers the context
  console.log("\nðŸ‘¤ User: Can you show me a simple example?");
  messages.push(new HumanMessage("Can you show me a simple example?"));

  const response2 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response2.content);

  // Third exchange - AI still remembers everything
  console.log("\nðŸ‘¤ User: What are the benefits compared to JavaScript?");
  messages.push(new AIMessage(response2.content));
  messages.push(new HumanMessage("What are the benefits compared to JavaScript?"));

  const response3 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response3.content);

  console.log("\n\nâœ… Notice how the AI maintains context throughout the conversation!");
  console.log(`ðŸ“Š Total messages in history: ${messages.length}`);
}

main().catch(console.error);
