/**
 * Multi-Turn Conversation
 * Run: npx tsx 02-chat-models/code/01-multi-turn.ts
 */

import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, AIMessage, SystemMessage } from "@langchain/core/messages";
import "dotenv/config";

async function main() {
  console.log("ðŸ’¬ Multi-Turn Conversation Example\n");

  const model = new ChatOpenAI({
    model: process.env.AI_MODEL,
    configuration: { baseURL: process.env.AI_ENDPOINT },
    apiKey: process.env.AI_API_KEY
  });

  // Start with system message and first question
  const messages = [
    new SystemMessage("You are a helpful coding tutor who gives clear, concise explanations."),
    new HumanMessage("What is TypeScript?"),
  ];

  console.log("ðŸ‘¤ User: What is TypeScript?");

  // First exchange
  const response1 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response1.content);
  messages.push(new AIMessage(String(response1.content)));

  // Second exchange - AI remembers the context
  console.log("\nðŸ‘¤ User: Can you show me a simple example?");
  messages.push(new HumanMessage("Can you show me a simple example?"));

  const response2 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response2.content);

  // Third exchange - AI still remembers everything
  console.log("\nðŸ‘¤ User: What are the benefits compared to JavaScript?");
  messages.push(new AIMessage(String(response2.content)));
  messages.push(new HumanMessage("What are the benefits compared to JavaScript?"));

  const response3 = await model.invoke(messages);
  console.log("\nðŸ¤– AI:", response3.content);

  console.log("\n\nâœ… Notice how the AI maintains context throughout the conversation!");
  console.log(`ðŸ“Š Total messages in history: ${messages.length}`);
}

main().catch(console.error);
